# -*- coding: utf-8 -*-
"""FLight2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qTXrUcufy1KkU05rT1dWqrtcotby6CiZ
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.impute import SimpleImputer
from sklearn.neural_network import MLPClassifier
from sklearn.preprocessing import LabelEncoder  # Add this import statement
from sklearn.metrics import accuracy_score

# Load your dataset
df = pd.read_csv("Clean_Dataset.csv")

# Drop rows after the 4500th index
df = df.iloc[:4500]

# Encode categorical variables
label_encoder = LabelEncoder()
categorical_cols = ['airline', 'flight', 'source_city', 'departure_time', 'stops', 'arrival_time', 'destination_city', 'class']
for col in categorical_cols:
    df[col] = label_encoder.fit_transform(df[col])

# Define features (X) and target variable (y)
X = df.drop(columns=['price'])
y = (df['price'] > 7000).astype(int)  # Set your desired threshold

# Repeat the process 10 times
for i in range(10):
    # Split the dataset into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=i)  # Use a different random state for each iteration

    # Handle missing values using imputation
    imputer = SimpleImputer(strategy='mean')
    X_train_imputed = imputer.fit_transform(X_train)
    X_test_imputed = imputer.transform(X_test)

    # Initialize and train the MLP classifier
    ann_classifier = MLPClassifier(random_state=42, max_iter=500)  # Set your desired parameters
    ann_classifier.fit(X_train_imputed, y_train)

    # Make predictions on the test set
    y_pred = ann_classifier.predict(X_test_imputed)

    # Evaluate the classifier
    accuracy = accuracy_score(y_test, y_pred)
    print(f'{accuracy*100:.2f}')

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import LabelEncoder  # Add this import statement
from sklearn.metrics import accuracy_score

# Load your dataset
df = pd.read_csv("Clean_Dataset.csv")

# Drop rows after the 4500th index
df = df.iloc[:4500]

# Encode categorical variables
label_encoder = LabelEncoder()
categorical_cols = ['airline', 'flight', 'source_city', 'departure_time', 'stops', 'arrival_time', 'destination_city', 'class']
for col in categorical_cols:
    df[col] = label_encoder.fit_transform(df[col])

# Define features (X) and target variable (y)
X = df.drop(columns=['price'])
y = (df['price'] > 7000).astype(int)  # Set your desired threshold

# Repeat the process 10 times
for i in range(10):
    # Split the dataset into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=i)  # Use a different random state for each iteration

    # Handle missing values using imputation
    imputer = SimpleImputer(strategy='mean')
    X_train_imputed = imputer.fit_transform(X_train)
    X_test_imputed = imputer.transform(X_test)

    # Initialize and train the Logistic Regression model
    logistic_reg = LogisticRegression(random_state=42)
    logistic_reg.fit(X_train_imputed, y_train)

    # Make predictions on the test set
    y_pred = logistic_reg.predict(X_test_imputed)

    # Evaluate the model
    accuracy = accuracy_score(y_test, y_pred)
    print(f'{accuracy*100:.2f}')

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.impute import SimpleImputer
from sklearn.ensemble import AdaBoostClassifier
from sklearn.preprocessing import LabelEncoder  # Add this import statement
from sklearn.metrics import accuracy_score

# Load your dataset
df = pd.read_csv("Clean_Dataset.csv")

# Drop rows after the 4500th index
df = df.iloc[:4500]

# Encode categorical variables
label_encoder = LabelEncoder()
categorical_cols = ['airline', 'flight', 'source_city', 'departure_time', 'stops', 'arrival_time', 'destination_city', 'class']
for col in categorical_cols:
    df[col] = label_encoder.fit_transform(df[col])

# Define features (X) and target variable (y)
X = df.drop(columns=['price'])
y = (df['price'] > 7000).astype(int)  # Set your desired threshold

# Repeat the process 10 times
for i in range(10):
    # Split the dataset into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=i)  # Use a different random state for each iteration

    # Handle missing values using imputation
    imputer = SimpleImputer(strategy='mean')
    X_train_imputed = imputer.fit_transform(X_train)
    X_test_imputed = imputer.transform(X_test)

    # Initialize and train the AdaBoost classifier
    adaboost_classifier = AdaBoostClassifier(random_state=42)
    adaboost_classifier.fit(X_train_imputed, y_train)

    # Make predictions on the test set
    y_pred = adaboost_classifier.predict(X_test_imputed)

    # Evaluate the classifier
    accuracy = accuracy_score(y_test, y_pred)
    print(f'{accuracy*100:.2f}')

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.impute import SimpleImputer
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score

# Load your dataset
df = pd.read_csv("Clean_Dataset.csv")

# Encode categorical variables
label_encoder = LabelEncoder()
categorical_cols = ['airline', 'flight', 'source_city', 'departure_time', 'stops', 'arrival_time', 'destination_city', 'class']
for col in categorical_cols:
    df[col] = label_encoder.fit_transform(df[col])

# Define features (X) and target variable (y)
X = df.drop(columns=['price'])
y = (df['price'] > 7000).astype(int)  # Set your desired threshold

# Repeat the process 10 times
for i in range(10):
    # Split the dataset into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=i)  # Use a different random state for each iteration

    # Handle missing values using imputation
    imputer = SimpleImputer(strategy='mean')
    X_train_imputed = imputer.fit_transform(X_train)
    X_test_imputed = imputer.transform(X_test)

    # Initialize and train the Decision Tree classifier with reduced complexity
    dt_classifier = DecisionTreeClassifier(max_depth=3, min_samples_split=5, min_samples_leaf=2, random_state=42)  # Adjust these parameters
    dt_classifier.fit(X_train_imputed, y_train)

    # Make predictions on the test set
    y_pred = dt_classifier.predict(X_test_imputed)

    # Evaluate the classifier
    accuracy = accuracy_score(y_test, y_pred)
    print(f'{accuracy*100:.2f}')