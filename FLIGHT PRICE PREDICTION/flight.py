# -*- coding: utf-8 -*-
"""Flight.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11wF7A1QTZKnYO8dKlXkROc9g_jmlTrba
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, classification_report

# Load your dataset
df = pd.read_csv("Clean_Dataset.csv")

# Encode categorical variables
label_encoder = LabelEncoder()
categorical_cols = ['airline', 'flight', 'source_city', 'departure_time', 'stops', 'arrival_time', 'destination_city', 'class']
for col in categorical_cols:
    df[col] = label_encoder.fit_transform(df[col])

# Define features (X) and target variable (y)
X = df.drop(columns=['price'])
y = (df['price'] > 7000).astype(int)  # Set your desired threshold

# Repeat the process 10 times
for i in range(10):
    # Split the dataset into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=i)  # Use a different random state for each iteration

    # Initialize and train the KNN classifier
    knn_classifier = KNeighborsClassifier(n_neighbors=5)  # Set your desired k value
    knn_classifier.fit(X_train, y_train)

    # Make predictions on the test set
    y_pred = knn_classifier.predict(X_test)

    # Evaluate the classifier
    accuracy = accuracy_score(y_test, y_pred)
    print(f'{accuracy*100:.2f}')

# No need to display classification report in this case

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report

# Load your dataset
df = pd.read_csv("Clean_Dataset.csv")

# Encode categorical variables
label_encoder = LabelEncoder()
categorical_cols = ['airline', 'flight', 'source_city', 'departure_time', 'stops', 'arrival_time', 'destination_city', 'class']
for col in categorical_cols:
    df[col] = label_encoder.fit_transform(df[col])

# Define features (X) and target variable (y)
X = df.drop(columns=['price'])
y = (df['price'] > 7000).astype(int)  # Set your desired threshold

# Repeat the process 10 times
for i in range(10):
    # Split the dataset into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=i)  # Use a different random state for each iteration

    # Initialize and train the Random Forest classifier
    rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)  # Set your desired number of trees and random state
    rf_classifier.fit(X_train, y_train)

    # Make predictions on the test set
    y_pred = rf_classifier.predict(X_test)

    # Evaluate the classifier
    accuracy = accuracy_score(y_test, y_pred)
    print(f'{accuracy*100:.2f}')

# No need to display classification report in this case

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.impute import SimpleImputer
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score

# Load your dataset
df = pd.read_csv("Clean_Dataset.csv")

# Encode categorical variables
label_encoder = LabelEncoder()
categorical_cols = ['airline', 'flight', 'source_city', 'departure_time', 'stops', 'arrival_time', 'destination_city', 'class']
for col in categorical_cols:
    df[col] = label_encoder.fit_transform(df[col])

# Define features (X) and target variable (y)
X = df.drop(columns=['price'])
y = (df['price'] > 7000).astype(int)  # Set your desired threshold

# Repeat the process 10 times
for i in range(10):
    # Split the dataset into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=i)  # Use a different random state for each iteration

    # Handle missing values using imputation
    imputer = SimpleImputer(strategy='mean')
    X_train_imputed = imputer.fit_transform(X_train)
    X_test_imputed = imputer.transform(X_test)

    # Initialize and train the Decision Tree classifier
    dt_classifier = DecisionTreeClassifier(random_state=42)
    dt_classifier.fit(X_train_imputed, y_train)

    # Make predictions on the test set
    y_pred = dt_classifier.predict(X_test_imputed)

    # Evaluate the classifier
    accuracy = accuracy_score(y_test, y_pred)
    print(f'{accuracy*100:.2f}')

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, classification_report

# Load your dataset
df = pd.read_csv("Clean_Dataset.csv")

# Encode categorical variables
label_encoder = LabelEncoder()
categorical_cols = ['airline', 'flight', 'source_city', 'departure_time', 'stops', 'arrival_time', 'destination_city', 'class']
for col in categorical_cols:
    df[col] = label_encoder.fit_transform(df[col])

# Define features (X) and target variable (y)
X = df.drop(columns=['price'])
y = (df['price'] > 7000).astype(int)  # Set your desired threshold

# Repeat the process 10 times
for i in range(10):
    # Split the dataset into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=i)  # Use a different random state for each iteration

    # Initialize and train the XGBoost classifier
    xgb_classifier = XGBClassifier(n_estimators=100, random_state=42)  # Set your desired number of boosting rounds and random state
    xgb_classifier.fit(X_train, y_train)

    # Make predictions on the test set
    y_pred = xgb_classifier.predict(X_test)

    # Evaluate the classifier
    accuracy = accuracy_score(y_test, y_pred)
    print(f'{accuracy*100:.2f}')

# No need to display classification report in this case

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.impute import SimpleImputer
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score

# Load your dataset
df = pd.read_csv("Clean_Dataset.csv")

# Encode categorical variables
label_encoder = LabelEncoder()
categorical_cols = ['airline', 'flight', 'source_city', 'departure_time', 'stops', 'arrival_time', 'destination_city', 'class']
for col in categorical_cols:
    df[col] = label_encoder.fit_transform(df[col])

# Define features (X) and target variable (y)
X = df.drop(columns=['price'])
y = (df['price'] > 7000).astype(int)  # Set your desired threshold

# Repeat the process 10 times
for i in range(10):
    # Split the dataset into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=i)  # Use a different random state for each iteration

    # Handle missing values using imputation
    imputer = SimpleImputer(strategy='mean')
    X_train_imputed = imputer.fit_transform(X_train)
    X_test_imputed = imputer.transform(X_test)

    # Initialize and train the MLP classifier
    ann_classifier = MLPClassifier(random_state=42, max_iter=500)  # Set your desired parameters
    ann_classifier.fit(X_train_imputed, y_train)

    # Make predictions on the test set
    y_pred = ann_classifier.predict(X_test_imputed)

    # Evaluate the classifier
    accuracy = accuracy_score(y_test, y_pred)
    print(f'Accuracy {i+1}: {accuracy:.2f}')