# -*- coding: utf-8 -*-
"""Untitled6.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Gk3ub5iabMwsPIXaYpZZBaGF8Fpzd9Dx
"""

# Import necessary libraries
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_absolute_error

# Load your dataset
dataset = pd.read_csv('Energy_consumption.csv')

# Extract features and target variable
X = dataset[['Temperature', 'Humidity', 'SquareFootage', 'Occupancy', 'HVACUsage', 'LightingUsage', 'RenewableEnergy', 'DayOfWeek', 'Holiday']]
y = dataset['EnergyConsumption']

# Convert categorical variables to numerical using LabelEncoder
label_encoder = LabelEncoder()
X['Occupancy'] = label_encoder.fit_transform(X['Occupancy'])
X['HVACUsage'] = label_encoder.fit_transform(X['HVACUsage'])
X['LightingUsage'] = label_encoder.fit_transform(X['LightingUsage'])
X['DayOfWeek'] = label_encoder.fit_transform(X['DayOfWeek'])
X['Holiday'] = label_encoder.fit_transform(X['Holiday'])

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Set up a loop to iterate over different values of n_neighbors
for n_neighbors in range(1, 11):
    # Initialize the KNN regressor
    knn_model = KNeighborsRegressor(n_neighbors=n_neighbors)

    # Train the model
    knn_model.fit(X_train, y_train)

    # Make predictions on the test set
    y_pred = knn_model.predict(X_test)

    # Evaluate the model
    mae = mean_absolute_error(y_test, y_pred)
    print(f'n_neighbors = {n_neighbors}, Mean Absolute Error: {mae}')

# Import necessary libraries
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix

# Load your dataset
dataset = pd.read_csv('Energy_consumption.csv')

# Extract features and target variable
X = dataset[['Temperature', 'Humidity', 'SquareFootage', 'Occupancy', 'HVACUsage', 'LightingUsage', 'RenewableEnergy', 'DayOfWeek', 'Holiday']]
y = dataset['EnergyConsumption']

# Convert categorical variables to numerical using LabelEncoder
label_encoder = LabelEncoder()
X['Occupancy'] = label_encoder.fit_transform(X['Occupancy'])
X['HVACUsage'] = label_encoder.fit_transform(X['HVACUsage'])
X['LightingUsage'] = label_encoder.fit_transform(X['LightingUsage'])
X['DayOfWeek'] = label_encoder.fit_transform(X['DayOfWeek'])
X['Holiday'] = label_encoder.fit_transform(X['Holiday'])

# Binarize the target variable for binary classification
y_binary = (y > y.median()).astype(int)

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y_binary, test_size=0.2, random_state=42)

# Set up a loop to iterate over different values of C (inverse of regularization strength)
for c_value in [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000, 100000, 1000000]:
    # Initialize the Logistic Regression model
    logistic_model = LogisticRegression(C=c_value, max_iter=1000)  # Increase max_iter to avoid convergence warning

    # Train the model
    logistic_model.fit(X_train, y_train)

    # Make predictions on the test set
    y_pred = logistic_model.predict(X_test)

    # Evaluate the model
    accuracy = accuracy_score(y_test, y_pred)
    confusion_mat = confusion_matrix(y_test, y_pred)
    print(f'C = {c_value}, Accuracy: {accuracy}, Confusion Matrix:\n{confusion_mat}')

# Import necessary libraries
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score, confusion_matrix

# Load your dataset
dataset = pd.read_csv('Energy_consumption.csv')

# Extract features and target variable
X = dataset[['Temperature', 'Humidity', 'SquareFootage', 'Occupancy', 'HVACUsage', 'LightingUsage', 'RenewableEnergy', 'DayOfWeek', 'Holiday']]
y = dataset['EnergyConsumption']

# Convert categorical variables to numerical using LabelEncoder
label_encoder = LabelEncoder()
X['Occupancy'] = label_encoder.fit_transform(X['Occupancy'])
X['HVACUsage'] = label_encoder.fit_transform(X['HVACUsage'])
X['LightingUsage'] = label_encoder.fit_transform(X['LightingUsage'])
X['DayOfWeek'] = label_encoder.fit_transform(X['DayOfWeek'])
X['Holiday'] = label_encoder.fit_transform(X['Holiday'])

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize the Gaussian Naive Bayes model
nb_model = GaussianNB()

# Train the model
nb_model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = nb_model.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
confusion_mat = confusion_matrix(y_test, y_pred)

print(f'Accuracy: {accuracy}, Confusion Matrix:\n{confusion_mat}')

pip install pandas scikit-learn

# Import necessary libraries
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error

# Load your dataset
dataset = pd.read_csv('Energy_consumption.csv')

# Extract features and target variable
X = dataset[['Temperature', 'Humidity', 'SquareFootage', 'Occupancy', 'HVACUsage', 'LightingUsage', 'RenewableEnergy', 'DayOfWeek', 'Holiday']]
y = dataset['EnergyConsumption']

# Convert categorical variables to numerical using LabelEncoder if needed

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize the Linear Regression model
linear_model = LinearRegression()

# Train the model
linear_model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = linear_model.predict(X_test)

# Evaluate the model
mae = mean_absolute_error(y_test, y_pred)
print(f'Mean Absolute Error: {mae}')

# Optionally, you can print the coefficients and intercept
print('Coefficients:', linear_model.coef_)
print('Intercept:', linear_model.intercept_)