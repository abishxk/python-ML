# -*- coding: utf-8 -*-
"""women.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14Pt6TSBS0qKnCNIcLWrhY2_0ytbH5n-h
"""

#random forest
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import LabelEncoder

# Read the dataset
df = pd.read_csv('Wellbeing_and_lifestyle_data_Kaggle.csv')

# Drop rows where GENDER is "Male"
df = df[df['GENDER'] != 'Male']

# Define the threshold for good/poor work-life balance
threshold = 668

df['WORK_LIFE_BALANCE_CLASS'] = df['WORK_LIFE_BALANCE_SCORE'].apply(lambda x: 1 if x > threshold else 0)

le = LabelEncoder()
df['BMI_RANGE'] = le.fit_transform(df['BMI_RANGE'])
df['GENDER'] = le.fit_transform(df['GENDER'])

X = df.drop(['WORK_LIFE_BALANCE_SCORE', 'WORK_LIFE_BALANCE_CLASS', 'Timestamp', 'AGE'], axis=1)
y = df['WORK_LIFE_BALANCE_CLASS']

# Print 10 accuracies
for i in range(10):
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=i)

    rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)

    rf_classifier.fit(X_train, y_train)

    y_pred = rf_classifier.predict(X_test)

    accuracy = accuracy_score(y_test, y_pred)
    print("Accuracy :")
    print(f"{accuracy:.4f}")

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import LabelEncoder

df = pd.read_csv('Wellbeing_and_lifestyle_data_Kaggle.csv')

# Assuming df is your dataset
df = df[df['GENDER'] != 'Male']

threshold = 668

df['WORK_LIFE_BALANCE_CLASS'] = df['WORK_LIFE_BALANCE_SCORE'].apply(lambda x: 1 if x > threshold else 0)

le = LabelEncoder()
df['BMI_RANGE'] = le.fit_transform(df['BMI_RANGE'])
df['GENDER'] = le.fit_transform(df['GENDER'])

X = df.drop(['WORK_LIFE_BALANCE_SCORE', 'WORK_LIFE_BALANCE_CLASS', 'Timestamp', 'AGE'], axis=1)
y = df['WORK_LIFE_BALANCE_CLASS']

# Print 10 accurate accuracies
for i in range(10):
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=i)

    # Increase the number of estimators and decrease the learning rate
    gb_classifier = GradientBoostingClassifier(n_estimators=200, learning_rate=0.01, max_depth=5, random_state=42)

    gb_classifier.fit(X_train, y_train)

    y_pred = gb_classifier.predict(X_test)

    accuracy = accuracy_score(y_test, y_pred)

    print(f"{accuracy*100:.2f}")

#KNN
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import LabelEncoder

df = pd.read_csv('Wellbeing_and_lifestyle_data_Kaggle.csv')
# Assuming df is your dataset
df = df[df['GENDER'] != 'Male']

threshold = 668

df['WORK_LIFE_BALANCE_CLASS'] = df['WORK_LIFE_BALANCE_SCORE'].apply(lambda x: 1 if x > threshold else 0)

le = LabelEncoder()
df['BMI_RANGE'] = le.fit_transform(df['BMI_RANGE'])
df['GENDER'] = le.fit_transform(df['GENDER'])

X = df.drop(['WORK_LIFE_BALANCE_SCORE', 'WORK_LIFE_BALANCE_CLASS', 'Timestamp', 'AGE'], axis=1)
y = df['WORK_LIFE_BALANCE_CLASS']

# Print 10 accuracies
for i in range(10):
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=i)

    knn_classifier = KNeighborsClassifier()

    knn_classifier.fit(X_train, y_train)

    y_pred = knn_classifier.predict(X_test)

    accuracy = accuracy_score(y_test, y_pred)
    print("Accuracy :")
    print(f"{accuracy:.4f}")

#svm
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import LabelEncoder

df = pd.read_csv('Wellbeing_and_lifestyle_data_Kaggle.csv')
# Assuming df is your dataset
df = df[df['GENDER'] != 'Male']

threshold = 668

df['WORK_LIFE_BALANCE_CLASS'] = df['WORK_LIFE_BALANCE_SCORE'].apply(lambda x: 1 if x > threshold else 0)

le = LabelEncoder()
df['BMI_RANGE'] = le.fit_transform(df['BMI_RANGE'])
df['GENDER'] = le.fit_transform(df['GENDER'])

X = df.drop(['WORK_LIFE_BALANCE_SCORE', 'WORK_LIFE_BALANCE_CLASS', 'Timestamp', 'AGE'], axis=1)
y = df['WORK_LIFE_BALANCE_CLASS']

# Print 10 accuracies
for i in range(10):
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=i)

    svm_classifier = SVC()

    svm_classifier.fit(X_train, y_train)

    y_pred = svm_classifier.predict(X_test)

    accuracy = accuracy_score(y_test, y_pred)
    print("Accuracy :")
    print(f"{accuracy:.4f}")

#decision tree
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import LabelEncoder

df = pd.read_csv('Wellbeing_and_lifestyle_data_Kaggle.csv')
# Assuming df is your dataset
df = df[df['GENDER'] != 'Male']

threshold = 668

df['WORK_LIFE_BALANCE_CLASS'] = df['WORK_LIFE_BALANCE_SCORE'].apply(lambda x: 1 if x > threshold else 0)

le = LabelEncoder()
df['BMI_RANGE'] = le.fit_transform(df['BMI_RANGE'])
df['GENDER'] = le.fit_transform(df['GENDER'])

X = df.drop(['WORK_LIFE_BALANCE_SCORE', 'WORK_LIFE_BALANCE_CLASS', 'Timestamp', 'AGE'], axis=1)
y = df['WORK_LIFE_BALANCE_CLASS']

# Print 10 accuracies
for i in range(10):
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=i)

    dt_classifier = DecisionTreeClassifier()

    dt_classifier.fit(X_train, y_train)

    y_pred = dt_classifier.predict(X_test)

    accuracy = accuracy_score(y_test, y_pred)
    print("Accuracy :")
    print(f"{accuracy:.4f}")